

services:
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    user: root                            # <- forÃ§ando root
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - HOME=/root                       
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DEFAULT_REGION=us-east-1
      #-PYSPARK_SUBMIT_ARGS=--packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.postgresql:postgresql:42.6.0 pyspark-shell
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 pyspark-shell
    ports:
      - "7077:7077"       
      - "8080:8080"       
    volumes:
      - ./src:/src
      - ./app:/app
      - ./sql:/sql

    networks:
      - spark-network

  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DEFAULT_REGION=us-east-1
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 pyspark-shell
    networks:
      - spark-network
    

  localstack:
    container_name: localstack
    image: localstack/localstack
    ports:
      - "4566:4566"         # LocalStack Gateway
      - "127.0.0.1:4510-4559:4510-4559"
    environment:
      - DEBUG=${DEBUG:-1}
      - SERVICES=s3,athena,glue,redshift
      - DEFAULT_REGION=us-east-1
    volumes:
      - "${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"
    networks:
      - spark-network

  jupyter-pyspark:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: jupyter_pyspark
    ports:
      - "8888:8888"
    environment:
      - PYSPARK_PYTHON=python3
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_OPTS=--master spark://spark-master:7077
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DEFAULT_REGION=us-east-1
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 pyspark-shell
    volumes:
      - ./notebooks:/home/jovyan/work
    depends_on:
      - spark-master
    networks:
      - spark-network
  
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: JONANOV
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: CVM
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"  
    restart: always
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge

volumes:
  postgres-db-volume:
